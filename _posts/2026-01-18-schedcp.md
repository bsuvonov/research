---
layout: post
title: "Towards Agentic OS: An LLM Agent Framework for Linux Schedulers"
categories: []
tags: [sched_ext, scheduling, MCP, eBPF, MAS]
---


![cap.png](assets/img/schedcp/cap.png)

<h4 align="center">MLforsystem workshop'25</h4>

The paper presents **SchedCP**, a control-plane framework that lets **autonomous LLM agents** safely optimize Linux scheduling by separating **semantic reasoning (“what to optimize”)** from **system execution (“how to observe and act”)**. It pairs this with **sched-agent**, a multi-agent system that analyzes workloads and generates/deploys **sched_ext eBPF schedulers**, reporting up to **1.79× performance improvement** and **13× cost reduction** versus naive agentic approaches.

### 1 Introduction
Linux’s general-purpose scheduler policies (e.g., EEVDF) can’t directly infer what an application *actually* needs, causing a “semantic gap,” even though **sched_ext** makes safe custom schedulers possible via eBPF.

Prior RL-based approaches typically lack workload semantics and often only tune within a human-specified search space, while naive LLM coding is reported as slow/expensive and sometimes performance-regressing.

Their core move is to split autonomous optimization into **goal-inference** (extract goals/constraints from workload) and **policy-synthesis** (compile into an eBPF scheduler policy).

### 2 Motivation
They identify three blockers to practical scheduler optimization: (1) a **knowledge gap** between operators/users and kernel scheduling behavior, (2) the **expertise barrier** of kernel development, and (3) **dynamic workload behavior** (traffic and parallelism shift over time).  
LLMs can help via tool-assisted workload exploration, semantic reasoning about code/workloads, and synthesizing eBPF schedulers while keeping heavy inference out of the scheduler hot path by operating from the control plane.  
A “naive agent” experiment suggests direct LLM coding can be slow/expensive and sometimes unsafe/ineffective.

### 3 The SchedCP Framework Design and Implementation
SchedCP is a **secure, decoupled control plane** for OS optimization: AI decides *what* to optimize, while SchedCP controls *how* to observe/act via stable tools and defensive interfaces.

Design principles: **decoupling/role separation**, **safety-first interfaces** (treat agents as non-cautious; avoid root), **adaptive context provisioning** (progressive detail to manage token/context costs), and **composable atomic tools** (Unix-y building blocks).

Core services:

- **Workload Analysis Engine**: tiered profiling/tracing (`perf`, `stat`, `top`, etc.) access + post-deploy feedback.
- **Scheduler Policy Repository**: store/search/reuse schedulers + metrics to reduce regeneration cost.
- **Execution Verifier**: multi-stage validation (eBPF verifier + scheduler-specific checks + micro-VM testing + canary rollback).

![fig1.png](assets/img/schedcp/fig1.png)





### 4 sched-agent: A Multi-Agent Framework for OS Optimization
On top of SchedCP, sched-agent decomposes the loop into four specialized agents: **Observation**, **Planning**, **Execution**, and **Learning**, using separate contexts and tools to iteratively improve a scheduler without retraining.
- **Observation** builds a workload profile and states optimization goals.
- **Planning** chooses between configuring an existing scheduler, patching, or composing a new scheduler from repository primitives.
- **Execution** synthesizes artifacts and routes them through verification/deployment tooling.
- **Learning** updates the repository with results/contexts/anti-patterns.

### 5 Preliminary Evaluation
They evaluate across multiple scenarios, testing whether agents can configure existing schedulers, synthesize new ones, reduce cost, and improve via iteration.

Reported results include: **kernel compilation** speedups up to **1.79×** vs EEVDF after iterative refinement, and on **schbench** improvements of **2.11× P99 latency** and **1.60× throughput** after refinement.

For long-tail batch workloads, sched-agent identifies the pattern and implements **Longest Job First**, yielding ~**20% average latency reduction**, and reports large efficiency gains in generation time/cost.

![fig2.png](assets/img/schedcp/fig2.png)
